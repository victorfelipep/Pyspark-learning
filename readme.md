# ğŸ”¥ PySpark Learning â€“ Organizations Dataset

## ğŸ“ Description
This project is a **learning exercise with PySpark**, using a **fictitious dataset (`organizations-100.csv`)** that contains information about fictional organizations.  
The goal is to explore how to load data, manipulate it with PySpark DataFrame API, and run SQL queries over structured data.  

---

## ğŸš€ Features
- Initialize a local PySpark session.  
- Load a CSV dataset with schema inference.  
- Select and filter organizations by number of employees and founding year.  
- Order results and display the top organizations.  
- Create a temporary SQL view and query the data using Spark SQL.  

---

## ğŸ“‚ Project Structure
pyspark-learning/
- â”œâ”€â”€ organizations-100.csv # Fictitious dataset with organizations info
- â”œâ”€â”€ main.py # Main script with PySpark code
- â””â”€â”€ README.md # Documentation
- â””â”€â”€ requirements.txt

---

## ğŸ› ï¸ Technologies Used
- **Python 3.10+**  
- **PySpark**  

---

## âš™ï¸ Installation
Clone the repository and install dependencies:  
pip install -r requirements.txt

## â–¶ï¸ How to Run
Place the file organizations-100.csv in the project folder.

Run the script:
python main.py

## ğŸ“œ License
This project uses fictitious data created for learning purposes.

No real company or organization data is included.
